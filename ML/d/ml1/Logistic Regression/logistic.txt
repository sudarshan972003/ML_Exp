import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

# Generating 1D non-linearly separable data
np.random.seed(42)
X = np.random.uniform(-10, 10, 100).reshape(-1, 1)  # 100 random points between -10 and 10
y = (X[:, 0] > 0).astype(int)  # Class 0 for x < 0, class 1 for x > 0

# Adding some noise to make the classes not perfectly separable
y[np.random.randint(0, 100, 10)] = 1 - y[np.random.randint(0, 100, 10)]  # Flip labels randomly

# Training a Logistic Regression model
clf = LogisticRegression()
clf.fit(X, y)

# Plotting the data points
plt.figure(figsize=(10, 6))
# Use different colors for each class
plt.scatter(X[y == 0], y[y == 0], color='b', label='Class 0', alpha=0.7)  # Class 0 in blue
plt.scatter(X[y == 1], y[y == 1], color='r', label='Class 1', alpha=0.7)  # Class 1 in red

# Generate points for sigmoid curve (probability of class 1)
X_test = np.linspace(-10, 10, 300).reshape(-1, 1)
y_prob = clf.predict_proba(X_test)[:, 1]  # Probability of class 1

# Plot sigmoid curve
plt.plot(X_test, y_prob, color='k', label='Sigmoid Curve')

plt.title("Logistic Regression - Sigmoid Curve")
plt.xlabel("Feature")
plt.ylabel("Probability of Class 1")
plt.legend()
plt.grid(True)
plt.show()
